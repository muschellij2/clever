% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DVARS.R
\name{DVARS}
\alias{DVARS}
\title{DVARS}
\usage{
DVARS(
  X,
  normalize = TRUE,
  cutoff_DVARS = NULL,
  cutoff_DPD = 5,
  cutoff_ZD = qnorm(1 - 0.05/nrow(as.matrix(X))),
  verbose = FALSE
)
}
\arguments{
\item{X}{a \eqn{T \times N} numeric matrix representing an fMRI run. There should
not be any missing data (\code{NA} or \code{NaN}).}

\item{normalize}{Normalize the data as proposed in the original paper? Default:
 \code{TRUE}. Normalization removes constant-zero voxels, scales by 100 / the
 median of the mean image, and then centers each voxel on its mean.

 To replicate Afyouni and Nichols' procedure for the HCP MPP data, since the
 HCP scans are already normalized to 10,000, just divide the data by 100 and
 center the voxels on their means:

 \code{Y <- Y/100; DVARS(t(Y - apply(Y, 1, mean)))} where \code{Y} is the 
 \eqn{V \times T} data matrix.

 Note that while voxel centering doesn't affect DVARS, it does affect
 DPD and ZD.}

\item{cutoff_DVARS, cutoff_DPD, cutoff_ZD}{Numeric outlier cutoffs. Timepoints
exceeding these cutoffs will be flagged as outliers.}

\item{verbose}{Should occasional updates be printed? Default is \code{FALSE}.}
}
\description{
Computes the DSE decomposition and DVARS-related statistics.
}
\details{
Citation: Insight and inference for DVARS (Afyouni and Nichols, 2018)

github.com/asoroosh/DVARS
}
